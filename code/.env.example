# Performance Engineering Benchmark Environment Configuration
# Copy this file to .env or .env.local and fill in your values
# .env.local takes precedence over .env

# =============================================================================
# LLM Analysis Configuration
# =============================================================================

# Default LLM provider: anthropic or openai
LLM_PROVIDER=openai

# Enable/disable LLM analysis (set to false to skip LLM calls)
LLM_ANALYSIS_ENABLED=true
LLM_MAX_TOKENS=131072

# Anthropic (Claude) Configuration
ANTHROPIC_API_KEY=
ANTHROPIC_MODEL=claude-opus-4-5

# OpenAI Configuration  
OPENAI_API_KEY=
OPENAI_MODEL=gpt-5.1

# =============================================================================
# Profiling Configuration
# =============================================================================

# Default profile type: none, minimal, deep_dive, roofline
DEFAULT_PROFILE_TYPE=deep_dive

# Timeout multiplier for profiling operations
PROFILING_TIMEOUT_MULTIPLIER=1.0

# =============================================================================
# Hardware Configuration (optional overrides)
# =============================================================================

# Force specific GPU architecture detection
# GPU_ARCH=blackwell

# Override peak performance numbers (useful for custom/underclocked GPUs)
# PEAK_BF16_TFLOPS=5040
# PEAK_FP8_TFLOPS=10080
# HBM_BANDWIDTH_TBS=8.0

# =============================================================================
# Output Configuration
# =============================================================================

# Default artifacts directory
ARTIFACTS_DIR=./artifacts

# Log level: DEBUG, INFO, WARNING, ERROR
LOG_LEVEL=INFO

