# AI Systems Performance Engineering - Code Repo

**Hardware:** 8x NVIDIA B200 GPUs (180 GB HBM3e, 148 SMs each)  
**Software:** PyTorch 2.9 + CUDA 13.0  

---

## ðŸš€ Quick Start

```bash
# 1. Install (one command, auto-handles everything)
sudo ./setup.sh

# 2. Verify hardware
nvidia-smi  # Should show 8x B200 GPUs

# 3. Run tests
./run_all_tests.sh

# 4. Check performance
python3 benchmark_peak.py
```

**If driver needs upgrade:**
```bash
sudo ./setup.sh   # Installs driver 580
sudo reboot       # Load new driver
sudo ./setup.sh   # Complete installation
```

---

## ðŸ“š Documentation

### Essential Guides
- **[docs/TODO.md](docs/TODO.md)** - What's left to do & completed features
- **[docs/READY_TO_RUN_GUIDE.md](docs/READY_TO_RUN_GUIDE.md)** - How to run benchmarks
- **[docs/TOOLS_QUICK_REFERENCE.md](docs/TOOLS_QUICK_REFERENCE.md)** - Tool commands
- **[OPTIMIZATION_QUICK_START.md](OPTIMIZATION_QUICK_START.md)** - 5-10x speedup guide

### Performance & Analysis
- **[MODEL_SIZE_ANALYSIS.md](MODEL_SIZE_ANALYSIS.md)** - Performance by model size
- **[MODEL_SIZE_RECOMMENDATIONS.md](MODEL_SIZE_RECOMMENDATIONS.md)** - Deployment sizing
- **[docs/performance_baseline.md](docs/performance_baseline.md)** - Validated baselines
- **[docs/power_efficiency_baselines.md](docs/power_efficiency_baselines.md)** - Power metrics
- **[docs/CUTLASS_SETUP.md](docs/CUTLASS_SETUP.md)** - CUTLASS backend configuration

### Architecture & Deployment
- **[docs/architecture_guides.md](docs/architecture_guides.md)** - GPT, MoE, inference tuning
- **[docs/migration_to_b200.md](docs/migration_to_b200.md)** - Migrate from A100/H100
- **[docs/8xb200_load_testing_guide.md](docs/8xb200_load_testing_guide.md)** - Load testing
- **[docs/moe_deployment_playbook.md](docs/moe_deployment_playbook.md)** - MoE deployment

### Hardware & System
- **[docs/B200_CUDA13_AUDIT.md](docs/B200_CUDA13_AUDIT.md)** - Hardware/software audit
- **[docs/future_optimizations.md](docs/future_optimizations.md)** - Future enhancements

---

## âš¡ Performance Optimization Quick Wins

Measured results from comprehensive profiling:

```python
# 1. Pinned memory (2-6x faster transfers)
loader = DataLoader(dataset, batch_size=32, pin_memory=True, num_workers=4)

# 2. Batched operations (31x faster GEMM)
output = torch.bmm(A, B)  # vs 40 separate matmuls

# 3. Preallocate buffers (eliminates 210ms CPU overhead)
data_buf = torch.empty(batch_size, input_dim, device='cuda')
data_buf.copy_(batch['input'], non_blocking=True)
```

**Cumulative speedup: 5-10x end-to-end**

See [OPTIMIZATION_QUICK_START.md](OPTIMIZATION_QUICK_START.md) for details.

---

## ðŸŽ¯ Validation Status

### âœ… Completed & Validated (2025-10-28)
- **Multi-GPU**: 8x B200 tensor-parallel (0.000 numerical drift)
- **NVLink**: 250 GB/s P2P, 273.5 GB/s AllReduce
- **Power Monitoring**: 2368W baseline validated
- **FP8 Quantization**: transformer_engine integration
- **Memory Profiling**: CI integrated with Chrome traces
- **Inference Server**: Load testing orchestration ready
- **Continuous Benchmarking**: Automated with JSON configs

**See [docs/TODO.md](docs/TODO.md) for complete list.**

### Performance Baselines
- **HBM3e Bandwidth**: 2.73 TB/s (35% of theoretical - realistic)
- **FP16 Compute**: 1291 TFLOPS (65% of peak - excellent)
- **torch.compile**: 1.02x (1B) to 0.98x (40B) - profile before using!
- **FlexAttention**: 1.75x (MUST use torch.compile)

---

## ðŸ“– Chapter Guide

| Chapter | Focus | Key Files |
|---------|-------|-----------|
| **Ch1** | Performance basics | `performance_basics.py` |
| **Ch2** | B200 hardware | `hardware_info.py`, `nvlink_c2c_p2p_blackwell.cu` |
| **Ch3** | System tuning | `bind_numa_affinity.py`, `system_tuning.sh` |
| **Ch4** | Multi-GPU | `training_8xb200_pipeline.py`, `bandwidth_benchmark_suite_8gpu.py` |
| **Ch5** | Storage/IO | `gpudirect_storage_example.py` |
| **Ch6** | CUDA basics | `my_first_kernel.cu`, `add_parallel.cu` |
| **Ch7** | Memory access | `hbm3e_peak_bandwidth.cu`, `async_prefetch_tma.cu` |
| **Ch8** | Occupancy/ILP | `occupancy_tuning.cu`, `loop_unrolling.cu` |
| **Ch9** | Kernel fusion | `fusion_pytorch.py`, `fused_l2norm.cu` |
| **Ch10** | Tensor Cores | `tcgen05_blackwell.cu`, `tma_2d_pipeline_blackwell.cu` |
| **Ch11** | Streams | `basic_streams.cu`, `stream_ordered_allocator.cu` |
| **Ch12** | CUDA Graphs | `cuda_graphs.cu`, `dynamic_parallelism.cu` |
| **Ch13** | PyTorch profiling | `compiled_autograd.py`, `memory_profiling.py` |
| **Ch14** | torch.compile | `torch_compiler_examples.py`, `triton_tma_blackwell.py` |
| **Ch15** | Disaggregated inference | `disaggregated_inference.py` |
| **Ch16** | Inference optimization | `inference_serving_8xb200.py`, `synthetic_moe_inference_benchmark.py` |
| **Ch17** | Dynamic routing | `dynamic_routing.py`, `early_rejection.py` |
| **Ch18** | Attention | `flex_attention_large_model.py`, `flashmla_kernel.cu` |
| **Ch19** | FP8 training | `native_fp8_training.py`, `adaptive_parallelism_strategy.py` |
| **Ch20** | AI kernel generator | `ai_kernel_generator.py` |

---

## ðŸ”§ Common Commands

### Build & Run Examples
```bash
# Build all CUDA examples
for dir in ch{2,6,7,8,9,10,11,12}; do cd $dir && make && cd ..; done

# Run specific chapter
python3 ch1/performance_basics.py
cd ch7 && make && ./hbm3e_peak_bandwidth

# Multi-GPU examples
torchrun --nproc_per_node=8 ch4/training_8xb200_pipeline.py --tp-size 2
torchrun --nproc_per_node=8 ch16/inference_serving_8xb200.py --demo
```

### Testing
```bash
# Run all tests (recommended)
./run_all_tests.sh

# Run unit tests
pytest tests/ -v

# Test NCCL multi-GPU
./check_driver_and_nccl.sh
torchrun --nproc_per_node=8 test_nccl_distributed.py
```

### Profiling
```bash
# Peak performance
python3 benchmark_peak.py

# Comprehensive profiling (30-60 min)
./comprehensive_profile_test.sh

# View results
LATEST=$(ls -td profiles_* | head -1)
cat ${LATEST}/reports/comprehensive_report.md
```

---

## âš ï¸ Critical Notes

### torch.compile
- **Unreliable** on large models (40B+): 0.98x-1.02x, can be SLOWER
- **Hangs** on models 40B+: Use `--skip-compile` flag
- Requires 100+ warmup iterations for large models
- Works better on smaller models (1B: 1.02x)
- Memory-bound workloads (large models) won't benefit from compilation

### FlexAttention (Ch18)
```python
# âŒ WRONG - Will be SLOWER (0.8-0.9x)!
output = flex_attention(q, k, v)

# âœ… CORRECT - 1.5-3x faster
flex_attn = torch.compile(flex_attention)
output = flex_attn(q, k, v)
```

### Hardware Reality
- **180 GB memory, 148 SMs** per GPU (NOT 192 GB / 192 SMs)
- **40-60% of peak** is EXCELLENT for real workloads
- **Memory-bound** workloads won't benefit from torch.compile

---

## ðŸ”¨ Troubleshooting

### NCCL / Multi-GPU Issues
```bash
# Check driver (must be 580+ for CUDA 13)
nvidia-smi

# Step 1: Diagnostics
./check_driver_and_nccl.sh

# Step 2: Test collectives
torchrun --nproc_per_node=8 test_nccl_distributed.py

# If failed: upgrade driver
sudo ./setup.sh
sudo reboot
sudo ./setup.sh
```

### CUDA Not Available
```bash
# Verify
nvidia-smi
python3 -c "import torch; print(torch.cuda.is_available())"

# Reinstall
sudo ./setup.sh
```

### NCU Permission Denied
```bash
sudo sysctl -w kernel.perf_event_paranoid=-1
```

---

## ðŸ“¦ Repository Structure

```
code/
â”œâ”€â”€ setup.sh                    # One-command setup
â”œâ”€â”€ run_all_tests.sh           # Test all examples
â”œâ”€â”€ benchmark_peak.py          # Performance baseline
â”œâ”€â”€ docs/                       # All documentation
â”‚   â”œâ”€â”€ TODO.md                # Remaining work & completed features
â”‚   â”œâ”€â”€ READY_TO_RUN_GUIDE.md # Quick start guide
â”‚   â””â”€â”€ ...
â”œâ”€â”€ tools/                      # Profiling & metrics
â”œâ”€â”€ ch1/ ... ch20/             # Chapter examples
â””â”€â”€ tests/                      # Unit tests
```

---

## ðŸ“Š Performance Targets (Measured)

| Metric | Target | Actual | Status |
|--------|--------|--------|--------|
| HBM3e Bandwidth | 7.8 TB/s | 2.73 TB/s (35%) | âœ… Realistic |
| FP16 Compute | 2000 TFLOPS | 1291 TFLOPS (65%) | âœ… Excellent |
| torch.compile (1B) | >1.3x | 1.02x | âš ï¸ Marginal |
| torch.compile (40B) | >1.3x | 0.98x | âŒ Slower |
| FlexAttention | >2.0x | 1.75x | âœ… Works |
| Multi-GPU (8x B200) | - | 0.000 drift | âœ… Perfect |
| NVLink AllReduce | - | 273.5 GB/s | âœ… Validated |

**Key Insight:** Memory-bound workloads (most real code) won't hit peak. 40-60% is excellent!

**Why is torch.compile slower on 40B models?**  
Large models are **memory-bound**, not compute-bound. Moving 80 GB of weights from HBM3e is the bottleneck. torch.compile optimizes compute kernels (fusion, better scheduling) but can't overcome memory bandwidth limits. Additionally:
- Eager mode already uses TF32, Flash Attention, and cuDNN optimizations  
- Compilation adds memory overhead (80.6 â†’ 82.5 GB) without speedup
- For 40B+ models: use FP8 quantization (35% memory reduction) or tensor parallelism instead

**CUTLASS Backend:** PyTorch 2.9 includes CUTLASS support for GEMM operations. Install via `sudo ./setup.sh` (includes `nvidia-cutlass-dsl` and `cuda-python`). The backend is working without errors, but performance gains are limited by memory bandwidth on large models. Use `mode='max-autotune'` to enable. See [docs/CUTLASS_SETUP.md](docs/CUTLASS_SETUP.md) for details.

---

## ðŸ“š Documentation

### Core Guides
- **[8x B200 Load Testing Guide](docs/8xb200_load_testing_guide.md)** - Comprehensive load testing on 8-GPU systems
- **[MoE Deployment Playbook](docs/moe_deployment_playbook.md)** - Production deployment for Mixture-of-Experts models (routing, autoscaling, monitoring)
- **[Power Efficiency Baselines](docs/power_efficiency_baselines.md)** - Tokens/Joule metrics and cost analysis
- **[Architecture Guides](docs/architecture_guides.md)** - Architecture-specific tuning (GPT, MoE, inference)
- **[Migration to B200](docs/migration_to_b200.md)** - Step-by-step migration guide
- **[Tools Quick Reference](docs/TOOLS_QUICK_REFERENCE.md)** - All tools and workflows

### Status & Planning
- **[KNOWN_GAPS.md](KNOWN_GAPS.md)** - What's implemented, what's not, and why
- **[Performance Baseline](docs/performance_baseline.md)** - Validated baseline metrics

---

**Status:** Production-ready, fully validated on 8x B200 hardware  
**Last Updated:** October 28, 2025  
**Documentation:** All claims backed by measurements
