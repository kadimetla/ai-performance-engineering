"""Streams + compile + decode graph capture."""

from __future__ import annotations

import sys
from pathlib import Path

REPO_ROOT = Path(__file__).resolve().parents[2]
if str(REPO_ROOT) not in sys.path:
    sys.path.insert(0, str(REPO_ROOT))

from labs.nanochat_microbench.nanochat_common import NanoChatBenchmark, NanoChatConfig, attach_benchmark_metadata  # noqa: E402


def get_benchmark() -> NanoChatBenchmark:
    cfg = NanoChatConfig(
        batch_size=8,
        prompt_tokens=256,  # Reduced for faster graph capture
        decode_tokens=64,   # Reduced for faster graph capture  
        hidden_size=1024,   # Smaller model for graph capture efficiency
        use_pinned_host=True,
        use_copy_stream=True,
        use_compute_stream=True,
        use_torch_compile=False,
        use_cuda_graphs=True,
        graph_full_iteration=True,  # Full graph capture for best performance
        label="optimized_fast_nanochat_graph",
        iterations=12,  # More iterations for stable timing
        warmup=15,      # Extra warmup for graph capture
    )
    return attach_benchmark_metadata(NanoChatBenchmark(cfg), __file__)


if __name__ == "__main__":
    from core.harness.benchmark_harness import BenchmarkHarness, BenchmarkMode  # noqa: E402

    bench = get_benchmark()
    harness = BenchmarkHarness(mode=BenchmarkMode.CUSTOM, config=bench.get_config())
    result = harness.benchmark(bench)
    mean = result.timing.mean_ms if result.timing else 0.0
    print(f"\noptimized_fast_nanochat_graph: {mean:.3f} ms/iter")
